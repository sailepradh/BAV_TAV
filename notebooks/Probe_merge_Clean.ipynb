{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue with the different probe design in BAV project\n",
    "\n",
    "There are two different probe design i.e Probe_deisgn4_5 and Probe_design_6. Using these probes design gives completely different interaction calls for all the replicates, since earlier two biological replicates were used to generate the interaction while the third biological replicate HiCap interaction was done using probe design 6. Thus to deal with this issue, we had a meeting regarding this. The main resolutions of the meeting are as follows:\n",
    "\n",
    "* Use Deisgn 6 as the univeral probe design\n",
    "* Improve the negative control probe design using both design4_5 and design6\n",
    "\n",
    "Pseudo-code for script for fixing the issues:\n",
    "\n",
    "* Use the Design6 Transcipt file and SNV probe deisng files \n",
    "* For the transcript file, cluster the promoter isoforms (d = 1200 bp)\n",
    "    * for (+) strand ---> take the left most TSS\n",
    "    * for (-) strand ---> take the right most TSS\n",
    "* Generate the mock probe file named as MergedMockDesign4_5_6\n",
    "* Merge Negative control for Probe_design4_5 and probedesign6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Clustering of the promoters at 1200 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo do this first we gonna try few things:\\n\\n    * We first divide genes based on the strand\\n    * We then make a dictionary based start position of the gene \\n    * The key here will be the position of the gene and values will be the other fields\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part1 : Reading the probedeisngn6 \"Sorted_Ref_NC_ENSEMBL-transcropt.bed6sorted.dedup.txt\" \n",
    "## and generating the new transcript file wherein the promoter within 1200bp are clustered together\n",
    "## and generating a merged probe 4,5 and 6 transcript file\n",
    "\n",
    "\n",
    "'''\n",
    "To do this first we gonna try few things:\n",
    "\n",
    "    * We first divide genes based on the strand\n",
    "    * We then make a dictionary based start position of the gene \n",
    "    * The key here will be the position of the gene and values will be the other fields\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"-\" strand manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10866\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "probe_file = \"Sorted_Ref_PC_NC_ENSEMBL_transcript.bed6.sorted.dedup.txt\"\n",
    "\n",
    "## Generating a dictionary of probe_transcript that have the \"-\" strand annotation \n",
    "\n",
    "pro_tran_dict = {}\n",
    "with open (probe_file, \"r\") as probe:\n",
    "    for lines in probe:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        if line[5]  == \"-\":\n",
    "            postion_combine = line[0]+\":\"+line[1]+\":\"+line[2]+\":\"+line[3]+\":\"+\".\"+\":\"+line[5]\n",
    "            combo = pro_tran_dict.get(postion_combine, [])\n",
    "            test = line[6]\n",
    "            combo.append(test)\n",
    "            pro_tran_dict[postion_combine] = combo            \n",
    "\n",
    "len_con = []\n",
    "for keys, values in pro_tran_dict.items():\n",
    "    new_keys = keys+\":\"+values[0]\n",
    "    len_con.append(new_keys)\n",
    "    \n",
    "\n",
    "test = {}\n",
    "for ele in len_con:\n",
    "    break_set = ele.split(\":\")\n",
    "    gene = break_set [3]\n",
    "    distance_all = test.get(gene, [])\n",
    "    few_all = break_set[0],break_set[1],break_set[2],break_set[4],break_set[5],break_set[6]\n",
    "    distance_all.append(few_all)\n",
    "    test[gene] = distance_all \n",
    "\n",
    "print (len (test.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_trancript = []\n",
    "file_out = \"test_2.txt\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "for keys, values in test.items():\n",
    "    if len(values) >= 2:\n",
    "        nes = {}\n",
    "        distance = []\n",
    "        \n",
    "        for element in values:\n",
    "            position = element[2]\n",
    "            combo = nes.get(position, '')\n",
    "            combo = element[0], element[1],element[2],element[3],element[4],element[5]\n",
    "            nes[position] = combo\n",
    "            distance.append(position)\n",
    "            \n",
    "            counter = 0 \n",
    "            loop_counter = [0]\n",
    "            #print(distance)\n",
    "            new_dist = distance.copy()\n",
    "            mapping_dict ={}\n",
    "            \n",
    "            \n",
    "            for ele in distance:\n",
    "                #print(ele)\n",
    "                new_dist[counter] = int(ele)+1200\n",
    "                dist = int(ele)+1200\n",
    "                \n",
    "                newest = [v for i,v in enumerate(distance) if int(v) < dist ]\n",
    "                max_val = max(newest)\n",
    "                \n",
    "                counter=counter+1\n",
    "                new_dist = distance.copy()\n",
    "                #print(new_dist)\n",
    "                #print(max_val)\n",
    "                almost_there = mapping_dict.get(ele, '')\n",
    "                almost_there = str(max_val)\n",
    "                mapping_dict[ele] = almost_there \n",
    "                \n",
    "        uniq_dist = np.unique(list(mapping_dict.values()))\n",
    "                \n",
    "        #print(uniq_dist)\n",
    "            \n",
    "        for dis in uniq_dist:\n",
    "            fh.write (\"\\t\".join(nes[dis])+\"\\t\"+keys)\n",
    "            fh.write(\"\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    elif len(values) < 2:\n",
    "        for element in values:\n",
    "            all = []\n",
    "            \n",
    "            all.append (element[0])\n",
    "            all.append (element[1])\n",
    "            all.append (element[2])\n",
    "            all.append (element[3])\n",
    "            all.append (element[4])\n",
    "            all.append (element[5])\n",
    "            all.append(keys)\n",
    "        \n",
    "            fh.write(\"\\t\".join(all))\n",
    "            fh.write(\"\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"+\" strand manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "\n",
    "probe_file = \"Sorted_Ref_PC_NC_ENSEMBL_transcript.bed6.sorted.dedup.txt\"\n",
    "\n",
    "pro_tran_dict = {}\n",
    "with open (probe_file, \"r\") as probe:\n",
    "    for lines in probe:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        if line[5]  == \"+\":\n",
    "            postion_combine = line[0]+\":\"+line[1]+\":\"+line[2]+\":\"+line[3]+\":\"+\".\"+\":\"+line[5]\n",
    "            combo = pro_tran_dict.get(postion_combine, [])\n",
    "            test = line[6]\n",
    "            combo.append(test)\n",
    "            pro_tran_dict[postion_combine] = combo            \n",
    "\n",
    "len_con = []\n",
    "\n",
    "for keys, values in pro_tran_dict.items():\n",
    "    new_keys = keys+\":\"+values[0]\n",
    "    len_con.append(new_keys)\n",
    "    \n",
    "\n",
    "test = {}\n",
    "\n",
    "for ele in len_con:\n",
    "    break_set = ele.split(\":\")\n",
    "    gene = break_set [3]\n",
    "    distance_all = test.get(gene, [])\n",
    "    few_all = break_set[0],break_set[1],break_set[2],break_set[4],break_set[5],break_set[6]\n",
    "    distance_all.append(few_all)\n",
    "    test[gene] = distance_all \n",
    "\n",
    "print (len(list(test.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_out = \"test_2_+_strand.txt\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "for keys, values in test.items():\n",
    "    if len(values) >= 2:\n",
    "        nes = {}\n",
    "        distance = []\n",
    "        \n",
    "        for element in values:\n",
    "            position = element[1]\n",
    "            combo = nes.get(position, '')\n",
    "            combo = element[0], element[1],element[2],element[3],element[4],element[5]\n",
    "            nes[position] = combo\n",
    "            distance.append(position)\n",
    "            \n",
    "            counter = 0 \n",
    "            loop_counter = [0]\n",
    "            #print(distance)\n",
    "            new_dist = distance.copy()\n",
    "            mapping_dict ={}\n",
    "            \n",
    "            \n",
    "            for ele in distance:\n",
    "                #print(ele)\n",
    "                new_dist[counter] = int(ele)-1200\n",
    "                dist = int(ele)-1200\n",
    "                \n",
    "                newest = [v for i,v in enumerate(distance) if int(v) > dist ]\n",
    "                max_val = min(newest)\n",
    "                \n",
    "                counter=counter+1\n",
    "                new_dist = distance.copy()\n",
    "                #print(new_dist)\n",
    "                #print(max_val)\n",
    "                almost_there = mapping_dict.get(ele, '')\n",
    "                almost_there = str(max_val)\n",
    "                mapping_dict[ele] = almost_there \n",
    "                \n",
    "        uniq_dist = np.unique(list(mapping_dict.values()))\n",
    "                \n",
    "        #print(uniq_dist)\n",
    "            \n",
    "        for dis in uniq_dist:\n",
    "            fh.write (\"\\t\".join(nes[dis])+\"\\t\"+keys)\n",
    "            fh.write(\"\\n\")\n",
    "    \n",
    "    elif len(values) < 2:\n",
    "        for element in values:\n",
    "            all = []\n",
    "            \n",
    "            all.append (element[0])\n",
    "            all.append (element[1])\n",
    "            all.append (element[2])\n",
    "            all.append (element[3])\n",
    "            all.append (element[4])\n",
    "            all.append (element[5])\n",
    "            all.append(keys)\n",
    "            #all.append(keys)\n",
    "            fh.write(\"\\t\".join(all))\n",
    "            fh.write(\"\\n\")\n",
    "fh.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$3,$7,$4,$5,$6,$7}' test_2.txt > tmp; mv tmp test_2.txt \n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$3,$7,$4,$5,$6,$7}' test_2_+_strand.txt > tmp; mv tmp test_2_+_strand.txt\n",
    "cat test_2.txt test_2_+_strand.txt | sort  -k4,4 > Design6_hg19_probe_combined.txt\n",
    "#rm -r test_2.txt test_2_+_strand.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "\n",
    "file_out = \"test.gff3\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "header1= \"##gff-version 3.2.1\"\n",
    "header2 = \"##genome-build UCSC hg19\"\n",
    "\n",
    "fh.write(header1)\n",
    "fh.write(\"\\n\")\n",
    "fh.write(header2)\n",
    "fh.write(\"\\n\")\n",
    "\n",
    "target_set = (\"promoter\", \"SNP\")\n",
    "\n",
    "combined_deisgn = \"Design6_hg19_probe_combined.txt\"\n",
    "with open (combined_deisgn, \"r\") as design:\n",
    "    for lines in design:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        \n",
    "        probe = \"probe\"\n",
    "        transcript = \"transcriptid=\"+line[6]+\";\"\n",
    "        side = (\"R\",\"L\")\n",
    "        target = \"target=\"+target_set[0]+\";\"\n",
    "        design_name = \"design=MergedMockDesign;\"\n",
    "        feature_vicinity = \"featuresinvicinity=none;\"\n",
    "        name = \"Name=\"+line[-1]+\";\"\n",
    "        distance_tss =\"distancetotss=2500\"\n",
    "        \n",
    "        #print (line)\n",
    "        #break\n",
    "        if line[5]  == \"+\":\n",
    "            #print (line)\n",
    "            Right_probe_end = int(line[1])+2500\n",
    "            #Right_probe_start = Right_probe_end-120\n",
    "            Right_probe_start = int(line[1])\n",
    "            Left_probe_start = int(line[1])-2500\n",
    "            #Left_probe_end = Left_probe_start +120\n",
    "            Left_probe_end = int(line[1])\n",
    "            tss_target = \"targettss=\"+line[1]+\";\"\n",
    "            \n",
    "            #print(side)\n",
    "            \n",
    "            for side in side:\n",
    "                if side == \"R\":\n",
    "                    side1 = \"side=R;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                \n",
    "                else:\n",
    "                    side1 = \"side=L;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                    \n",
    "        else:\n",
    "            #print (line)\n",
    "            Right_probe_end = int(line[2])+2500\n",
    "            #Right_probe_start = Right_probe_end-120\n",
    "            Right_probe_start = int(line[2])\n",
    "            Left_probe_start = int(line[2])-2500\n",
    "            #Left_probe_end = Left_probe_start +120\n",
    "            Left_probe_end = int(line[2])\n",
    "            tss_target = \"targettss=\"+line[2]+\";\"\n",
    "            \n",
    "            #print(side)\n",
    "            \n",
    "            for side in side:\n",
    "                if side == \"R\":\n",
    "                    side1 = \"side=R;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                \n",
    "                else:\n",
    "                    side1 = \"side=L;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                                \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open (file_out, \"a\")\n",
    "file_out = \"test.gff3\"\n",
    "\n",
    "combined_deisgn = \"Design6_GWASSNPs6.txt\"\n",
    "target_set = (\"promoter\", \"SNP\")\n",
    "\n",
    "with open (combined_deisgn, \"r\") as design:\n",
    "    for lines in design:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        \n",
    "        #print (line)\n",
    "        \n",
    "        \n",
    "        probe = \"probe\"\n",
    "        transcript = \"transcriptid=\"+line[-1]+\";\"\n",
    "        side = (\"R\",\"L\")\n",
    "        target = \"target=\"+target_set[1]+\";\"\n",
    "        design_name = \"design=MergedMockDesign;\"\n",
    "        feature_vicinity = \"featuresinvicinity=none;\"\n",
    "        name = \"Name=\"+line[3]+\";\"\n",
    "        distance_tss =\"distancetotss=2500\"\n",
    "        \n",
    "        Right_probe_end = int(line[1])+2500\n",
    "        #Right_probe_start = Right_probe_end-120\n",
    "        Right_probe_start = int(line[1])\n",
    "        Left_probe_start = int(line[1])-2500\n",
    "        #Left_probe_end = Left_probe_start +120\n",
    "        Left_probe_end = int(line[1])\n",
    "        tss_target = \"targettss=\"+line[1]+\";\"\n",
    "        \n",
    "        for side in side:\n",
    "            if side == \"R\":\n",
    "                side1 = \"side=R;\"\n",
    "                all_name = [name, transcript, \n",
    "                            side1,target,design_name,\n",
    "                            feature_vicinity,tss_target,distance_tss]\n",
    "                fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                fh.write (fewest)\n",
    "                fh.write(\"\\n\")\n",
    "                \n",
    "            elif side == \"L\" and Left_probe_start > 0:\n",
    "                side1 = \"side=L\" \n",
    "                all_name = [name, transcript, \n",
    "                            side1,target,design_name,\n",
    "                            feature_vicinity,tss_target,distance_tss]\n",
    "                fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                fh.write (fewest)\n",
    "                fh.write(\"\\n\")\n",
    "        \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gff3 manipulation for the negative control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mv: test.gff3: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "sed 's/Design4_Design5/MergedMockDesign/g' Probes_Design4_5.uniq.exonspurged.NegCtrl.gff3 > tmp1.gff3\n",
    "sed '1,2d'  Design6.hg19.NegCtrlProbes.MboI.15.37.32_2017-08-25.1250.gff3  | sed 's/Design6/MergedMockDesign/g'  > tmp2.gff3\n",
    "\n",
    "cat  tmp1.gff3 tmp2.gff3 > Merged4.5.6.hg19.NegCtrlProbes.MboI.2019-01-16.gff3\n",
    "\n",
    "mv test.gff3 Merged4.5.6.hg19.AllProbes.MboI.2019-01-16.gff3\n",
    "rm -r tmp1.gff3 tmp2.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
