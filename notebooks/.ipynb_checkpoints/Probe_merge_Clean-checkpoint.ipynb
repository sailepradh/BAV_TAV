{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue with the different probe design in BAV project\n",
    "\n",
    "There are two different probe design i.e Probe_deisgn4_5 and Probe_design_6. Using these probes design gives completely different interaction calls for all the replicates, since earlier two biological replicates were used to generate the interaction while the third biological replicate HiCap interaction was done using probe design 6. Thus to deal with this issue, we had a meeting regarding this. The main resolutions of the meeting are as follows:\n",
    "\n",
    "* Use Deisgn 6 as the univeral probe design\n",
    "* Improve the negative control probe design using both design4_5 and design6\n",
    "\n",
    "Pseudo-code for script for fixing the issues:\n",
    "\n",
    "* Use the Design6 Transcipt file and SNV probe deisng files \n",
    "* For the transcript file, cluster the promoter isoforms (d = 1200 bp)\n",
    "    * for (+) strand ---> take the left most TSS\n",
    "    * for (-) strand ---> take the right most TSS\n",
    "* Generate the mock probe file named as MergedMockDesign4_5_6\n",
    "* Merge Negative control for Probe_design4_5 and probedesign6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Clustering of the promoters at 1200 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo do this first we gonna try few things:\\n\\n    * We first divide genes based on the strand\\n    * We then make a dictionary based start position of the gene \\n    * The key here will be the position of the gene and values will be the other fields\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part1 : Reading the probedeisngn6 \"Sorted_Ref_NC_ENSEMBL-transcropt.bed6sorted.dedup.txt\" \n",
    "## and generating the new transcript file wherein the promoter within 1200bp are clustered together\n",
    "## and generating a merged probe 4,5 and 6 transcript file\n",
    "\n",
    "\n",
    "'''\n",
    "To do this first we gonna try few things:\n",
    "\n",
    "    * We first divide genes based on the strand\n",
    "    * We then make a dictionary based start position of the gene \n",
    "    * The key here will be the position of the gene and values will be the other fields\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"-\" strand manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10866\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "probe_file = \"Sorted_Ref_PC_NC_ENSEMBL_transcript.bed6.sorted.dedup.txt\"\n",
    "\n",
    "## Generating a dictionary of probe_transcript that have the \"-\" strand annotation \n",
    "\n",
    "pro_tran_dict = {}\n",
    "with open (probe_file, \"r\") as probe:\n",
    "    for lines in probe:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        if line[5]  == \"-\":\n",
    "            postion_combine = line[0]+\":\"+line[1]+\":\"+line[2]+\":\"+line[3]+\":\"+\".\"+\":\"+line[5]\n",
    "            combo = pro_tran_dict.get(postion_combine, [])\n",
    "            test = line[6]\n",
    "            combo.append(test)\n",
    "            pro_tran_dict[postion_combine] = combo            \n",
    "\n",
    "len_con = []\n",
    "for keys, values in pro_tran_dict.items():\n",
    "    new_keys = keys+\":\"+values[0]\n",
    "    len_con.append(new_keys)\n",
    "    \n",
    "\n",
    "test = {}\n",
    "for ele in len_con:\n",
    "    break_set = ele.split(\":\")\n",
    "    gene = break_set [3]\n",
    "    distance_all = test.get(gene, [])\n",
    "    few_all = break_set[0],break_set[1],break_set[2],break_set[4],break_set[5],break_set[6]\n",
    "    distance_all.append(few_all)\n",
    "    test[gene] = distance_all \n",
    "\n",
    "print (len (test.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_trancript = []\n",
    "file_out = \"test_2.txt\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "for keys, values in test.items():\n",
    "    if len(values) >= 2:\n",
    "        nes = {}\n",
    "        distance = []\n",
    "        \n",
    "        for element in values:\n",
    "            position = element[2]\n",
    "            combo = nes.get(position, '')\n",
    "            combo = element[0], element[1],element[2],element[3],element[4],element[5]\n",
    "            nes[position] = combo\n",
    "            distance.append(position)\n",
    "            \n",
    "            counter = 0 \n",
    "            loop_counter = [0]\n",
    "            #print(distance)\n",
    "            new_dist = distance.copy()\n",
    "            mapping_dict ={}\n",
    "            \n",
    "            \n",
    "            for ele in distance:\n",
    "                #print(ele)\n",
    "                new_dist[counter] = int(ele)+1200\n",
    "                dist = int(ele)+1200\n",
    "                \n",
    "                newest = [v for i,v in enumerate(distance) if int(v) < dist ]\n",
    "                max_val = max(newest)\n",
    "                \n",
    "                counter=counter+1\n",
    "                new_dist = distance.copy()\n",
    "                #print(new_dist)\n",
    "                #print(max_val)\n",
    "                almost_there = mapping_dict.get(ele, '')\n",
    "                almost_there = str(max_val)\n",
    "                mapping_dict[ele] = almost_there \n",
    "                \n",
    "        uniq_dist = np.unique(list(mapping_dict.values()))\n",
    "                \n",
    "        #print(uniq_dist)\n",
    "            \n",
    "        for dis in uniq_dist:\n",
    "            fh.write (\"\\t\".join(nes[dis])+\"\\t\"+keys)\n",
    "            fh.write(\"\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    elif len(values) < 2:\n",
    "        for element in values:\n",
    "            all = []\n",
    "            \n",
    "            all.append (element[0])\n",
    "            all.append (element[1])\n",
    "            all.append (element[2])\n",
    "            all.append (element[3])\n",
    "            all.append (element[4])\n",
    "            all.append (element[5])\n",
    "            all.append(keys)\n",
    "        \n",
    "            fh.write(\"\\t\".join(all))\n",
    "            fh.write(\"\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"+\" strand manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "\n",
    "probe_file = \"Sorted_Ref_PC_NC_ENSEMBL_transcript.bed6.sorted.dedup.txt\"\n",
    "\n",
    "pro_tran_dict = {}\n",
    "with open (probe_file, \"r\") as probe:\n",
    "    for lines in probe:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        if line[5]  == \"+\":\n",
    "            postion_combine = line[0]+\":\"+line[1]+\":\"+line[2]+\":\"+line[3]+\":\"+\".\"+\":\"+line[5]\n",
    "            combo = pro_tran_dict.get(postion_combine, [])\n",
    "            test = line[6]\n",
    "            combo.append(test)\n",
    "            pro_tran_dict[postion_combine] = combo            \n",
    "\n",
    "len_con = []\n",
    "\n",
    "for keys, values in pro_tran_dict.items():\n",
    "    new_keys = keys+\":\"+values[0]\n",
    "    len_con.append(new_keys)\n",
    "    \n",
    "\n",
    "test = {}\n",
    "\n",
    "for ele in len_con:\n",
    "    break_set = ele.split(\":\")\n",
    "    gene = break_set [3]\n",
    "    distance_all = test.get(gene, [])\n",
    "    few_all = break_set[0],break_set[1],break_set[2],break_set[4],break_set[5],break_set[6]\n",
    "    distance_all.append(few_all)\n",
    "    test[gene] = distance_all \n",
    "\n",
    "print (len(list(test.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_out = \"test_2_+_strand.txt\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "for keys, values in test.items():\n",
    "    if len(values) >= 2:\n",
    "        nes = {}\n",
    "        distance = []\n",
    "        \n",
    "        for element in values:\n",
    "            position = element[1]\n",
    "            combo = nes.get(position, '')\n",
    "            combo = element[0], element[1],element[2],element[3],element[4],element[5]\n",
    "            nes[position] = combo\n",
    "            distance.append(position)\n",
    "            \n",
    "            counter = 0 \n",
    "            loop_counter = [0]\n",
    "            #print(distance)\n",
    "            new_dist = distance.copy()\n",
    "            mapping_dict ={}\n",
    "            \n",
    "            \n",
    "            for ele in distance:\n",
    "                #print(ele)\n",
    "                new_dist[counter] = int(ele)-1200\n",
    "                dist = int(ele)-1200\n",
    "                \n",
    "                newest = [v for i,v in enumerate(distance) if int(v) > dist ]\n",
    "                max_val = min(newest)\n",
    "                \n",
    "                counter=counter+1\n",
    "                new_dist = distance.copy()\n",
    "                #print(new_dist)\n",
    "                #print(max_val)\n",
    "                almost_there = mapping_dict.get(ele, '')\n",
    "                almost_there = str(max_val)\n",
    "                mapping_dict[ele] = almost_there \n",
    "                \n",
    "        uniq_dist = np.unique(list(mapping_dict.values()))\n",
    "                \n",
    "        #print(uniq_dist)\n",
    "            \n",
    "        for dis in uniq_dist:\n",
    "            fh.write (\"\\t\".join(nes[dis])+\"\\t\"+keys)\n",
    "            fh.write(\"\\n\")\n",
    "    \n",
    "    elif len(values) < 2:\n",
    "        for element in values:\n",
    "            all = []\n",
    "            \n",
    "            all.append (element[0])\n",
    "            all.append (element[1])\n",
    "            all.append (element[2])\n",
    "            all.append (element[3])\n",
    "            all.append (element[4])\n",
    "            all.append (element[5])\n",
    "            all.append(keys)\n",
    "            #all.append(keys)\n",
    "            fh.write(\"\\t\".join(all))\n",
    "            fh.write(\"\\n\")\n",
    "fh.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$3,$7,$4,$5,$6,$7}' test_2.txt > tmp; mv tmp test_2.txt \n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$3,$7,$4,$5,$6,$7}' test_2_+_strand.txt > tmp; mv tmp test_2_+_strand.txt\n",
    "cat test_2.txt test_2_+_strand.txt | sort  -k4,4 > Design6_hg19_probe_combined.txt\n",
    "#rm -r test_2.txt test_2_+_strand.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir (\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Feature_probe_file\")\n",
    "\n",
    "file_out = \"test.gff3\"\n",
    "fh = open (file_out, \"w\")\n",
    "\n",
    "header1= \"##gff-version 3.2.1\"\n",
    "header2 = \"##genome-build UCSC hg19\"\n",
    "\n",
    "fh.write(header1)\n",
    "fh.write(\"\\n\")\n",
    "fh.write(header2)\n",
    "fh.write(\"\\n\")\n",
    "\n",
    "target_set = (\"promoter\", \"SNP\")\n",
    "\n",
    "combined_deisgn = \"Design6_hg19_probe_combined.txt\"\n",
    "with open (combined_deisgn, \"r\") as design:\n",
    "    for lines in design:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        \n",
    "        probe = \"probe\"\n",
    "        transcript = \"transcriptid=\"+line[6]+\";\"\n",
    "        side = (\"R\",\"L\")\n",
    "        target = \"target=\"+target_set[0]+\";\"\n",
    "        design_name = \"design=MergedMockDesign;\"\n",
    "        feature_vicinity = \"featuresinvicinity=none;\"\n",
    "        name = \"Name=\"+line[-1]+\";\"\n",
    "        distance_tss =\"distancetotss=2500\"\n",
    "        \n",
    "        #print (line)\n",
    "        #break\n",
    "        if line[5]  == \"+\":\n",
    "            #print (line)\n",
    "            Right_probe_end = int(line[1])+2500\n",
    "            #Right_probe_start = Right_probe_end-120\n",
    "            Right_probe_start = int(line[1])\n",
    "            Left_probe_start = int(line[1])-2500\n",
    "            #Left_probe_end = Left_probe_start +120\n",
    "            Left_probe_end = int(line[1])\n",
    "            tss_target = \"targettss=\"+line[1]+\";\"\n",
    "            \n",
    "            #print(side)\n",
    "            \n",
    "            for side in side:\n",
    "                if side == \"R\":\n",
    "                    side1 = \"side=R;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                \n",
    "                else:\n",
    "                    side1 = \"side=L;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                    \n",
    "        else:\n",
    "            #print (line)\n",
    "            Right_probe_end = int(line[2])+2500\n",
    "            #Right_probe_start = Right_probe_end-120\n",
    "            Right_probe_start = int(line[2])\n",
    "            Left_probe_start = int(line[2])-2500\n",
    "            #Left_probe_end = Left_probe_start +120\n",
    "            Left_probe_end = int(line[2])\n",
    "            tss_target = \"targettss=\"+line[2]+\";\"\n",
    "            \n",
    "            #print(side)\n",
    "            \n",
    "            for side in side:\n",
    "                if side == \"R\":\n",
    "                    side1 = \"side=R;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                \n",
    "                else:\n",
    "                    side1 = \"side=L;\"\n",
    "                    all_name = [name, transcript, \n",
    "                                side1,target,design_name,\n",
    "                                feature_vicinity,tss_target,distance_tss]\n",
    "                    fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                    fh.write (fewest)\n",
    "                    fh.write(\"\\n\")\n",
    "                                \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open (file_out, \"a\")\n",
    "file_out = \"test.gff3\"\n",
    "\n",
    "combined_deisgn = \"Design6_GWASSNPs6.txt\"\n",
    "target_set = (\"promoter\", \"SNP\")\n",
    "\n",
    "chr_all = [\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\n",
    "           \"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\",\n",
    "           \"chr11\",\"chr12\",\"chr13\",\"chr14\",\"chr15\",\n",
    "           \"chr16\",\"chr17\",\"chr18\",\"chr19\",\"chr20\",\n",
    "           \"chr21\",\"chr22\",\"chrX\",\"chrY\"]\n",
    "\n",
    "target_set = (\"promoter\", \"SNP\")\n",
    "\n",
    "with open (combined_deisgn, \"r\") as design:\n",
    "    for lines in design:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        \n",
    "        #print (line)     \n",
    "        probe = \"probe\"\n",
    "        transcript = \"transcriptid=\"+line[-1]+\";\"\n",
    "        side = (\"R\",\"L\")\n",
    "        target = \"target=\"+target_set[1]+\";\"\n",
    "        design_name = \"design=MergedMockDesign;\"\n",
    "        feature_vicinity = \"featuresinvicinity=none;\"\n",
    "        name = \"Name=\"+line[3]+\";\"\n",
    "        distance_tss =\"distancetotss=2500\"\n",
    "        \n",
    "        Right_probe_end = int(line[1])+2500\n",
    "        #Right_probe_start = Right_probe_end-120\n",
    "        Right_probe_start = int(line[1])\n",
    "        Left_probe_start = int(line[1])-2500\n",
    "        #Left_probe_end = Left_probe_start +120\n",
    "        Left_probe_end = int(line[1])\n",
    "        tss_target = \"targettss=\"+line[1]+\";\"\n",
    "        \n",
    "        for side in side:\n",
    "            if side == \"R\" and line[0] in chr_all:\n",
    "                side1 = \"side=R;\"\n",
    "                all_name = [name, transcript, \n",
    "                            side1,target,design_name,\n",
    "                            feature_vicinity,tss_target,distance_tss]\n",
    "                fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Right_probe_start)+\"\\t\"+str(Right_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                fh.write (fewest)\n",
    "                fh.write(\"\\n\")\n",
    "                \n",
    "            elif side == \"L\" and line[0] in chr_all:\n",
    "                side1 = \"side=L\" \n",
    "                all_name = [name, transcript, \n",
    "                            side1,target,design_name,\n",
    "                            feature_vicinity,tss_target,distance_tss]\n",
    "                fewest = line[0]+\"\\t\"+\".\"+\"\\t\"+probe+\"\\t\"+str(Left_probe_start)+\"\\t\"+str(Left_probe_end)+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\".\"+\"\\t\"+\" \".join(all_name)\n",
    "                fh.write (fewest)\n",
    "                fh.write(\"\\n\")\n",
    "        \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gff3 manipulation for the negative control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mv: test.gff3: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "sed 's/Design4_Design5/MergedMockDesign/g' Probes_Design4_5.uniq.exonspurged.NegCtrl.gff3 > tmp1.gff3\n",
    "sed '1,2d'  Design6.hg19.NegCtrlProbes.MboI.15.37.32_2017-08-25.1250.gff3  | sed 's/Design6/MergedMockDesign/g'  > tmp2.gff3\n",
    "\n",
    "cat  tmp1.gff3 tmp2.gff3 > Merged4.5.6.hg19.NegCtrlProbes.MboI.2019-01-16.gff3\n",
    "\n",
    "mv test.gff3 Merged4.5.6.hg19.AllProbes.MboI.2019-01-16.gff3\n",
    "rm -r tmp1.gff3 tmp2.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106345198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2129053+104216145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23822"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2243933 - 2220111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Interaction calling in two different conditions\n",
    "\n",
    "\n",
    "awk -v OFS=\"\\t\"  '{ if ($11-$10 < 100000) print $0}' BAVTAV.Proximities.Probe_Distal_SP4_p001_filtered.txt > BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_filtered.txt \n",
    "\n",
    " awk '{  print $1\":\"$2\":\"$3\":\"$9\":\"$10\":\"$11\":\"$12,$13,$16,$19,$22,$25,$28}' BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_filtered.txt  > Supporting_pairs_count.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Volumes/Work_drive/prj/BAV_TAV/data/raw_internal/Interaction_callsFeb/Differential_Interaction/\")\n",
    "\n",
    "DL_called = \"DL_Loop_all.tsv\"\n",
    "DL_dict = {}\n",
    "with open (DL_called , 'r') as diff_file:\n",
    "    next(diff_file)\n",
    "    for lines in diff_file:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        Gene_identifier = line[0]\n",
    "        other_fields  = DL_dict.get(Gene_identifier, '')\n",
    "        other_fields = line[1:6]\n",
    "        #test.append(other_fields)\n",
    "        DL_dict[Gene_identifier]= other_fields   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCC2:NM_000392:ABCC2_101542354:chr10:101534593:101542978:-7761 ['-0.249399810280739', '-0.984425042586216', '0.142988622229484', '0.705327810207816', '0.94424001882002']\n"
     ]
    }
   ],
   "source": [
    "for keys, values in DL_dict.items():\n",
    "    print (keys, values)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_file = \"BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_filtered.txt\"\n",
    "\n",
    "header = [\"RefSeqName\",\t\"TranscriptName\",\t\"Feature_ID\",\t\"Feature_Chr\",\t\"Feature_Start\",\t\"Feature_End\",\t\"Annotation\",\t\"Strand\",\t\"Interactor_Chr\",\t\"Interactor_Start\",\t\"Interactor_End\",\t\"distance\",\t\"TAV2431_SuppPairs\",\t\"TAV2431_p_value\",\t\"TAV2431_StrandCombination\",\t\"TAV2515_SuppPairs\",\t\"TAV2515_p_value\",\t\"TAV2515_StrandCombination\",\t\"TAV2709_SuppPairs\",\t\"TAV2709_p_value\",\t\"TAV2709_StrandCombination\",\t\"BAV2375_SuppPairs\",\t\"BAV2375_p_value\",\t\"BAV2375_StrandCombination\",\t\"BAV2424_SuppPairs\",\t\"BAV2424_p_value\",\t\"BAV2424_StrandCombination\",\t\"BAV2714_SuppPairs\",\t\"BAV2714_p_value\",\t\"BAV2714_StrandCombination\",\t\"logFC\",\t\"logCPM\",\t\"LR\",\t\"PValue\",\t\"p_adjust\"]\n",
    "\n",
    "\n",
    "out_file_2 = \"BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_DL_filtered.txt\"\n",
    "\n",
    "fh = open (out_file_2, \"w\")\n",
    "fh.write(\"\\t\".join(header))\n",
    "fh.write(\"\\n\")\n",
    "\n",
    "\n",
    "with open (interaction_file, 'r') as interact_file:\n",
    "    for lines in interact_file:\n",
    "        line = lines.strip().split(\"\\t\")\n",
    "        #print (line)\n",
    "        identifier = \":\".join([line[0],line[1],line[2],line[8],line[9],line[10],line[11]])\n",
    "        #print (identifier)\n",
    "        if identifier in DL_dict.keys():\n",
    "            line.append(DL_dict[identifier][0])\n",
    "            line.append(DL_dict[identifier][1])\n",
    "            line.append(DL_dict[identifier][2])\n",
    "            line.append(DL_dict[identifier][3])\n",
    "            line.append(DL_dict[identifier][4])\n",
    "            \n",
    "            fh.write (\"\\t\".join(line))\n",
    "            fh.write (\"\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "\n",
    "awk '{if ($NF < 0.05 && $31 < -1.5) print $0}'  BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_DL_filtered.txt > BAV_specific_interaction.txt\n",
    "\n",
    "awk '{if ($NF < 0.05 && $31 > 1.5) print $0}'  BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_DL_filtered.txt > TAV_specific_interaction.txt\n",
    "\n",
    "\n",
    "awk '{if ($NF < 0.05 && $31 > 2) print $0}'  BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_DL_filtered.txt > TAV_specific_interaction.txt\n",
    "\n",
    "\n",
    "awk '{if ($NF < 0.05 && $31 < -2) print $0}'  BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_DL_filtered.txt > BAV_specific_interaction.txt\n",
    "\n",
    "\n",
    "\n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$12,$13,$16,$19,$22,$25,$28,$NF}' BAV_specific_interaction.txt | awk '{print $1}' | sort | uniq > Genes_BAV.txt\n",
    "\n",
    "\n",
    "awk -F \"\\t\" -v OFS=\"\\t\" '{print $1,$2,$12,$13,$16,$19,$22,$25,$28,$NF}' TAV_specific_interaction.txt | awk '{print $1}' | sort | uniq > Genes_TAV.txt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/crex/proj/g2018023/nobackup/private/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAV specific interaction\n",
    "\n",
    "\n",
    "MLLT10  NM_001324297  MLLT10_21822277 chr10 21822277  22032559  1 + chr10 22618836  22619031  796559  8 2.18662e-06 0_0_4_4 16  0 0_0_4_12  9 0.000442346 0_0_9_0 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0\n",
    "LMO3  NM_001243612  LMO3_16760084 chr12 16760084  16701305  1 - chr12 16079620  16080013  -680464 7 0.000105111 4_0_3_0 9 9.33002e-08 0_0_3_6 11  1.85752e-05 0_3_0_8 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "LMO3  NM_001243612  LMO3_16760084 chr12 16760084  16701305  1 - chr12 18217539  18218100  1457455 6 0.000139611 0_0_3_3 6 0.000156767 0_0_3_3 9 0.000211407 0_0_9_0 0 1 0_0_0_0 0 1 0_0_0_0 0 1\n",
    "FLRT2 NM_001346144  FLRT2_85996368  chr14 85996368  86095040  1 + chr14 85226825  85227331  -769543 6 0.000704606 0_0_6_0 6 0.000531067 0_0_3_3 9 0.000449257 0_0_0_9 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "rs2121070 _Blood_pressure_gwa rs2121070_76650763  chr14 76650763  76650764  2 + chr14 76525698  76526537  -125065 18  6.668e-13 2_0_8_8 8 0.0008502 0_2_4_2 20  1.00568e-10 0_0_10_10 0 1 0_0_0\n",
    "LRRC46  NM_033413 LRRC46_45908992 chr17 45908992  45915079  1 + chr17 75154207  75186682  29245215  6 0.000113597 0_6_0_0 8 8.21765e-08 2_6_0_0 9 9.06283e-05 0_9_0_0 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "MRPL10  NM_145255 MRPL10_45908907 chr17 45908907  45900637  1 - chr17 75154207  75186682  29245300  6 0.000113597 0_6_0_0 8 8.21765e-08 2_6_0_0 9 9.06283e-05 0_9_0_0 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "ZNF532  NM_001318726  ZNF532_56529831 chr18 56529831  56653712  1 + chr18 56745683  56745796  215852  12  1.55933e-07 5_0_7_0 19  0 5_10_4_0  12  4.23337e-05 5_0_7_0 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "FSTL1 NM_007085 FSTL1_120169918 chr3  120169918 120113060 1 - chr3  119365819 119366969 -804099 8 2.05506e-06 0_0_4_4 7 3.22176e-05 2_1_4_0 11  1.11704e-05 1_0_6_4 0 1 0_0_0_0 0 1 0_0_0_0 0 1\n",
    "SULT1E1 NM_005420 SULT1E1_70725870  chr4  70725870  70706929  1 - chr4  73836136  73842479  3110266 6 7.84936e-05 0_2_0_4 9 3.75791e-10 0_1_4_4 8 0.000578896 0_0_0_8 0 1 0_0_0_0 0 1 0_0_0_0 0\n",
    "GRXCR2  NM_001080516  GRXCR2_145252531  chr5  145252531 145239295 1 - chr5  145461080 145461770 208549  8 0.000899318 8_0_0_0 10  2.0521e-06  4_6_0_0 14  1.36521e-06 2_6_0_6 0 1 0_0_0_0 0 1 0\n",
    "(END)\n",
    "\n",
    "\n",
    "### BAV specific interaction\n",
    "\n",
    "rs4590817 _Blood_pressure_gwa rs4590817_63467552  chr10 63467552  63467553  2 + chr10 62584203  62584829  -883349 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 6 0.000892326 0_0_4_2 6 0.000509739 0_0_0\n",
    "ZEB1  NM_001323638  ZEB1_31607423 chr10 31607423  31818742  1 + chr10 31980261  31980481  372838  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 17  0 6_0_0_11  36  0 6_0_6_24  16  5.443e-10 0_0_16_0\n",
    "ZEB1  NM_001323638  ZEB1_31607423 chr10 31607423  31818742  1 + chr10 31984441  31984832  377018  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  2.95248e-09 0_0_0_12  12  5.36649e-11 6_6_0_0 12  6.0\n",
    "ZEB1  NM_001323638  ZEB1_31607423 chr10 31607423  31818742  1 + chr10 32269586  32270182  662163  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  6.74949e-12 6_0_0_6 6 0.000865634 0_0_0_6 9 0.0005489\n",
    "BUD13 NM_001159736  BUD13_116643714 chr11 116643714 116618885 1 - chr11 113983708 113984331 -2660006  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 6 8.68203e-05 0_4_2_0 6 0.000101541 0_2_2_2 8 0.00073\n",
    "PLEKHB1 NM_001130033  PLEKHB1_73357222  chr11 73357222  73373864  1 + chr11 73835512  73836155  478290  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  2.86965e-10 0_7_1_4 8 1.10751e-05 0_0_4_4 9 0.0\n",
    "LINC00615 ENST00000546725.1 LINC00615_91311799  chr12 91311799  91342446  1 + chr12 90354468  90355368  -957331 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 8 5.24398e-06 2_0_6_0 8 1.30979e-06 2_0_6_0\n",
    "LMO3  NM_001243612  LMO3_16760084 chr12 16760084  16701305  1 - chr12 15477898  15479170  -1282186  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 15  0 0_0_12_3  9 9.74993e-09 0_0_6_3 9 0.000225795 0_0\n",
    "rs2072376 _GM12878_C_gwa  rs2072376_6579811 chr12 6579811 6579812 2 + chr12 6712107 6713219 132296  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  9.35246e-06 0_0_6_6 8 0.000702201 0_0_4_4 12  0.000\n",
    "SLC38A1 NM_001278389  SLC38A1_46660278  chr12 46660278  46576839  1 - chr12 45938038  45940453  -722240 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  1.28497e-12 6_3_0_3 6 0.000671138 0_0_0_6 9 0.0\n",
    "BMP4  NM_130851 BMP4_54421768 chr14 54421768  54416454  1 - chr14 56806154  56811379  2384386 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 10  6.35225e-12 5_0_5_0 6 0.000110887 6_0_0_0 8 0.000845193 0\n",
    "DAD1  NM_001344 DAD1_23058143 chr14 23058143  23033806  1 - chr14 23344512  23345688  286369  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 8 0.00044439  3_0_4_1 7 0.000597236 0_0_3_4 12  1.51532e-05 0\n",
    "MYO5A NM_000259 MYO5A_52821247  chr15 52821247  52599479  1 - chr15 48683781  48687120  -4137466  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 6 8.76093e-05 0_2_2_2 8 4.41544e-08 4_0_4_0 8 0.000625279\n",
    "CAB39 NM_016289 CAB39_231577556 chr2  231577556 231685790 1 + chr2  234393366 234398631 2815810 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 11  1.88738e-14 0_1_4_6 10  8.80385e-12 0_0_6_4 8 0.0008868\n",
    "LINC01114 ENST00000424321.5 LINC01114_105372213 chr2  105372213 105363095 1 - chr2  105424944 105425218 52731 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 12  0.000441499 0_0_3_9 14  7.14648e-08 0_2_3\n",
    "ECE2  NM_001037324  ECE2_183993798  chr3  183993798 184010819 1 + chr3  183637207 183638337 -356591 0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 8 0.000209257 2_2_4_0 8 3.60621e-05 0_0_6_2 16  7.29658\n",
    "SMC4  NM_001002800  SMC4_160117091  chr3  160117091 160152749 1 + chr3  158490041 158493436 -1627050  0 1 0_0_0_0 0 1 0_0_0_0 0 1 0_0_0_0 6 0.000180506 0_0_0_6 6 0.000175554 0_0_3_3 12  2.587\n",
    "(END)\n",
    "\n",
    "\n",
    "https://www.ahajournals.org/doi/10.1161/CIR.0000000000000606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining H3K27ac files \n",
    "\n",
    "\n",
    " ```shell\n",
    "  \n",
    "  \n",
    "## root file = /domus/h1/sail/BavTav\n",
    "\n",
    "##BAV\n",
    "  \n",
    "awk -v OFS=\"\\t\" '{print \"chr\"$1,$2,$3}' BAV2737acetyl_S10.sort.dup.bam_peaks.narrowPeak |sort -k 1,1 -k2,2n > BAV2737_H3K27ac.bed\n",
    "  \n",
    "awk -v OFS=\"\\t\" '{print \"chr\"$1,$2,$3}' BAV2742acetyl_S6.sort.dup.bam_peaks.narrowPeak |sort -k 1,1 -k2,2n > BAV2742_H3K27ac.bed\n",
    "  \n",
    "bedtools intersect -a BAV2737_H3K27ac.bed -b BAV2742_H3K27ac.bed  -wa -wb  > BAV_Replicates\n",
    "  \n",
    "############\n",
    "awk '{ if (($2 == $5) && ($3 == $6)) print $1,$2,$3}' BAV_Replicates > 0.txt\n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 < $5) ) print $1,$2,$3}' BAV_Replicates > 1.txt\n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 > $5) ) print $1,$5,$3}' BAV_Replicates > 2.txt\n",
    "  \n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 < $6) ) print $1,$2,$6}' BAV_Replicates > 3.txt\n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 > $6) ) print $1,$2,$3}' BAV_Replicates > 4.txt\n",
    "\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 > $6) ) print $1,$2,$3}' BAV_Replicates  > 5.txt \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 > $6) ) print $1,$2,$3}' BAV_Replicates  > 6.txt\n",
    " \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 < $6) ) print $1,$2,$6}' BAV_Replicates  > 7.txt\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 < $6) ) print $1,$5,$6}' BAV_Replicates  > 8.txt\n",
    " \n",
    "cat 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt  |sort -k 1,1 -k2,2n |uniq |awk -v OFS=\"\\t\" '{print $1,$2,$3}' > tmp ; mv tmp BAV_Replicates.bed \n",
    "\n",
    "bedtools merge -i BAV_Replicates.bed  > tmp ; mv tmp BAV_Replicates.bed\n",
    "\n",
    "\n",
    "rm -r *.txt\n",
    "\n",
    "\n",
    "\n",
    "##TAV \n",
    "\n",
    "awk -v OFS=\"\\t\" '{print \"chr\"$1,$2,$3}' TAV2519acetyl_S3_R1_001.fastq.gz.sort.dup.bam_peaks.narrowPeak |sort -k 1,1 -k2,2n > TAV2519_H3K27ac.bed\n",
    "\n",
    "awk -v OFS=\"\\t\" '{print \"chr\"$1,$2,$3}' TAV2675acetyl_S8_R1_001.fastq.gz.sort.dup.bam_peaks.narrowPeak |sort -k 1,1 -k2,2n > TAV2675_H3K27ac.bed\n",
    "\n",
    "bedtools intersect -a TAV2519_H3K27ac.bed -b TAV2675_H3K27ac.bed  -wa -wb  > TAV_Replicates\n",
    "\n",
    "##############\n",
    "awk '{ if (($2 == $5) && ($3 == $6)) print $1,$2,$3}' BAV_Replicates > 0.txt\n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 < $5) ) print $1,$2,$3}' TAV_Replicates > 1.txt \n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 > $5) ) print $1,$5,$3}' TAV_Replicates > 2.txt\n",
    "  \n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 < $6) ) print $1,$2,$6}' TAV_Replicates > 3.txt\n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 > $6) ) print $1,$2,$3}' TAV_Replicates > 4.txt\n",
    "\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 > $6) ) print $1,$2,$3}' TAV_Replicates  > 5.txt \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 > $6) ) print $1,$2,$3}' TAV_Replicates  > 6.txt\n",
    " \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 < $6) ) print $1,$2,$6}' TAV_Replicates  > 7.txt\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 < $6) ) print $1,$5,$6}' TAV_Replicates  > 8.txt\n",
    " \n",
    "cat 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt  |sort -k 1,1 -k2,2n |uniq |awk -v OFS=\"\\t\" '{print $1,$2,$3}' > tmp ; mv tmp TAV_Replicates.bed \n",
    "\n",
    "bedtools merge -i TAV_Replicates.bed   > tmp ; mv tmp TAV_Replicates.bed \n",
    "\n",
    "rm -r *.txt\n",
    " \n",
    " \n",
    "## Complete overlap for both of these \n",
    "## testing with complete overlap \n",
    " \n",
    " \n",
    "bedtools intersect -a BAV_Replicates.bed  -b TAV_Replicates.bed  -wa -wb > BAV_TAV_Replicates\n",
    "\n",
    "awk -v OFS=\"\\t\" '{print $1,$2,$3}' BAV_TAV_Replicates  |sort -k 1,1 -k2,2n |uniq > In_BAV.bed\n",
    "grep -vf In_BAV.bed  BAV_Replicates.bed  > BAV_Unique.bed\n",
    "\n",
    "\n",
    "awk -v OFS=\"\\t\" '{print $4,$5,$6}' BAV_TAV_Replicates  |sort -k 1,1 -k2,2n |uniq > In_TAV.bed\n",
    "grep -vf In_TAV.bed  TAV_Replicates.bed  > TAV_Unique.bed\n",
    "\n",
    "\n",
    "awk '{ if (($2 == $5) && ($3 == $6)) print $1,$2,$3}' BAV_TAV_Replicates > 0.txt   \n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 < $5) ) print $1,$2,$3}' BAV_TAV_Replicates > 1.txt \n",
    "awk '{ if (($2 != $5) && ($3 == $6) && ($2 > $5) ) print $1,$5,$3}' BAV_TAV_Replicates > 2.txt\n",
    "  \n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 < $6) ) print $1,$2,$6}' BAV_TAV_Replicates > 3.txt\n",
    "awk '{ if (($2 == $5) && ($3 != $6) && ($3 > $6) ) print $1,$2,$3}' BAV_TAV_Replicates > 4.txt\n",
    "\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 > $6) ) print $1,$5,$3}' BAV_TAV_Replicates > 5.txt \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 > $6) ) print $1,$2,$3}' BAV_TAV_Replicates  > 6.txt\n",
    " \n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 < $5) &&  ($3 < $6) ) print $1,$2,$6}' BAV_TAV_Replicates  > 7.txt\n",
    "awk '{ if (($2 != $5) && ($3 != $6) && ($2 > $5) &&  ($3 < $6) ) print $1,$5,$6}' BAV_TAV_Replicates  > 8.txt \n",
    " \n",
    " \n",
    "cat 0.txt 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt  |sort -k 1,1 -k2,2n |uniq |awk -v OFS=\"\\t\" '{print $1,$2,$3}' > tmp ; mv tmp BAVTAV_Replicates.bed \n",
    "\n",
    "\n",
    "cat BAVTAV_Replicates.bed BAV_Unique.bed TAV_Unique.bed|sort -k 1,1 -k2,2n |uniq  > tmp; mv tmp BAVTAV_new_Replicates.bed\n",
    "\n",
    "bedtools merge -i BAVTAV_new_Replicates.bed  > BAVTAV_Replicates_Merge.bed \n",
    " \n",
    "bedtools intersect -wao -a Digest_hg19_MboI_None_11-39-03_22-01-2016.2.bed -b BAVTAV_Replicates_Merge.bed > Fragments_andOverlapInfo.txt\n",
    " \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random set and enrichment analysis of H3K27ac in significant interaction datasets\n",
    "\n",
    "```shell\n",
    "sed '1d' BAVTAV.Proximities.Probe_Distal_SP4_p001_Len_filtered.txt |awk -v OFS=\"\\t\" '{print $9,$10,$11}'  | sort -k 1,1 -k2,2 | uniq > sorted_uniq_PD_Interaction.bed \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.366666666666667"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14050/1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
